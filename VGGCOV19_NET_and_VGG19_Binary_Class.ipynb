{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGGCOV19-NET and VGG19 Binary Class.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyONIgqNttos+ddYo/VaA1kW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akaraci/COVID-19/blob/master/VGGCOV19_NET_and_VGG19_Binary_Class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCJDdNzTS6ew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autotime\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "import pickle\n",
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import scikitplot as skplt\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, Adamax\n",
        "#from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn import metrics\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "from keras.callbacks import EarlyStopping\n",
        "np.random.seed(1000)\n",
        "\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Flatten\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import  ImageDataGenerator, img_to_array, load_img\n",
        "from glob import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOFWvmvdSCRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = pickle.load(open(\"drive/My Drive/Datacovid_kemal/X_tum.pickle\", \"rb\"))\n",
        "y = pickle.load(open(\"drive/My Drive/Datacovid_kemal/Y_tum.pickle\", \"rb\"))\n",
        "X = X/255.0 \n",
        "y = to_categorical(y, num_classes = 3)\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=5, shuffle=False)\n",
        "for train_index, test_index in kf.split(X):\n",
        "    \n",
        "    x_train = X[train_index]\n",
        "    y_train = y[train_index]\n",
        "    x_test = X[test_index]\n",
        "    y_test = y[test_index]\n",
        "    print(x_train.shape)\n",
        "    print(x_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SunXRIu9Sagi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VGGCOV19-NET Binary Class Code\n",
        "%load_ext autotime\n",
        "X = pickle.load(open(\"drive/My Drive/Datacovid_kemal/X_tum_two.pickle\", \"rb\"))\n",
        "y = pickle.load(open(\"drive/My Drive/Datacovid_kemal/Y_tum_two.pickle\", \"rb\"))\n",
        "\n",
        "# normalizing data (a pixel goes from 0 to 255)\n",
        "X = X/255.0   \n",
        "y = to_categorical(y, num_classes = 2)\n",
        "\n",
        "\n",
        "vgg=VGG19(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))   #include_top=False fully connected layer'ı iptal eder\n",
        "vgg_layer_list=vgg.layers\n",
        "model=Sequential()\n",
        "for layer in vgg_layer_list:\n",
        "    model.add(layer)\n",
        "\n",
        "for layer in model.layers:\n",
        "    layer.trainable=False\n",
        "\n",
        "numberOfClass=2\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(Dense(256))\n",
        "model.add(Dense(512))\n",
        "model.add(Dense(numberOfClass,activation='softmax'))\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=5, shuffle=False)\n",
        "aucs = []\n",
        "tprs = []\n",
        "fprs = []\n",
        "base_fpr = np.linspace(0, 1, 101)\n",
        "history=[]\n",
        "acc_val=[]\n",
        "result=[]\n",
        "plt.figure(figsize=(10, 10))\n",
        "fold=1\n",
        "opt=keras.optimizers.Adam(lr=0.001)\n",
        "for train_index, test_index in kf.split(X):\n",
        "    \n",
        "    x_train = X[train_index]\n",
        "    y_train = y[train_index]\n",
        "    x_test = X[test_index]\n",
        "    y_test = y[test_index]\n",
        "    \n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt,  metrics=[\"accuracy\"])\n",
        "    history = model.fit(x_train, y_train, batch_size=32,epochs=100, verbose=0) #validation_split=0.2   validation_data=(x_test, y_test)\n",
        "    \n",
        "    np.save(\"drive/My Drive/Datacovid_kemal/modelsmodifytwo/my_historyw\"+str(fold)+\".npy\",history.history)\n",
        "    \n",
        "    result.append(model.predict(x_test))\n",
        "    prediction = model.predict(x_test)\n",
        "    Y_pred_classes = np.argmax(prediction,axis = 1) \n",
        "    y_test_classes = np.argmax(y_test,axis = 1)\n",
        "    print(metrics.confusion_matrix(y_test_classes, Y_pred_classes))\n",
        "    print(metrics.classification_report(y_test_classes, Y_pred_classes, digits=2))\n",
        "    conf_mat =confusion_matrix(y_test_classes, Y_pred_classes, labels=[0, 1])\n",
        "    print(conf_mat)\n",
        "    total1=sum(sum(conf_mat))\n",
        "    accuracy1=(conf_mat[0,0]+conf_mat[1,1])/total1\n",
        "    acc_val.append(accuracy1)\n",
        "    print ('Accuracy : ', accuracy1)\n",
        "    probas_ = model.predict_proba(x_test)\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_test_classes, probas_[:, 1],drop_intermediate=False,pos_label=1)\n",
        "    roc_auc = metrics.auc(fpr, tpr)\n",
        "    print(\"Auc-\"+str(fold)+\"=\",roc_auc)\n",
        "    aucs.append(roc_auc)\n",
        "    plt.plot(fpr, tpr, lw=1, alpha=0.3,label='ROC Fold- %d (AUC = %0.2f)' % (fold, roc_auc))\n",
        "    tpr = np.interp(base_fpr, fpr, tpr)\n",
        "    tpr[0] = 0.0\n",
        "    tprs.append(tpr)\n",
        "    fold=fold+1\n",
        "mean_auc=np.mean(aucs)\n",
        "print(\"Mean AUC:\",mean_auc)\n",
        "mean_acc=np.mean(acc_val)\n",
        "print(\"Mean ACC:\",mean_acc)\n",
        "tprs = np.array(tprs)\n",
        "mean_tprs = tprs.mean(axis=0)\n",
        "mean_auc1 = metrics.auc(base_fpr, mean_tprs)\n",
        "std = tprs.std(axis=0)\n",
        "\n",
        "tprs_upper = np.minimum(mean_tprs + std, 1)\n",
        "tprs_lower = mean_tprs - std\n",
        "std_auc = np.std(aucs)\n",
        "plt.plot(base_fpr, mean_tprs, \n",
        "          label='Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
        "          lw=2, alpha=.8)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='Chance', alpha=.8)    \n",
        "plt.xlim([-0.01, 1.01])\n",
        "plt.ylim([-0.01, 1.01])\n",
        "plt.xlabel('False Positive Rate',fontsize=18)\n",
        "plt.ylabel('True Positive Rate',fontsize=18)\n",
        "plt.title('Cross-Validation ROC of Model-4 ')\n",
        "plt.legend(loc=\"lower right\", prop={'size': 15})\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VeB9yDBZ2G0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VGG19-NET Binary Class Code\n",
        "%load_ext autotime\n",
        "X = pickle.load(open(\"drive/My Drive/Datacovid_kemal/X_tum_two.pickle\", \"rb\"))\n",
        "y = pickle.load(open(\"drive/My Drive/Datacovid_kemal/Y_tum_two.pickle\", \"rb\"))\n",
        "\n",
        "# normalizing data (a pixel goes from 0 to 255)\n",
        "X = X/255.0   \n",
        "y = to_categorical(y, num_classes = 2)\n",
        "\n",
        "\n",
        "vgg=VGG19(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))   #include_top=False fully connected layer canceled\n",
        "\n",
        "model=Sequential()\n",
        "for layer in vgg_layer_list:\n",
        "    model.add(layer)\n",
        "\n",
        "\n",
        "for layer in model.layers:\n",
        "    layer.trainable=False\n",
        "\n",
        "numberOfClass=2\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096))\n",
        "model.add(Dense(4096))\n",
        "model.add(Dense(numberOfClass,activation='softmax'))\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=5, shuffle=False)\n",
        "aucs = []\n",
        "tprs = []\n",
        "fprs = []\n",
        "base_fpr = np.linspace(0, 1, 101)\n",
        "history=[]\n",
        "acc_val=[]\n",
        "result=[]\n",
        "plt.figure(figsize=(10, 10))\n",
        "fold=1\n",
        "opt=keras.optimizers.Adam(lr=0.001)\n",
        "for train_index, test_index in kf.split(X):\n",
        "    \n",
        "    x_train = X[train_index]\n",
        "    y_train = y[train_index]\n",
        "    x_test = X[test_index]\n",
        "    y_test = y[test_index]\n",
        "    \n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt,  metrics=[\"accuracy\"])\n",
        "    history = model.fit(x_train, y_train, batch_size=32,epochs=100, verbose=0) \n",
        "    \n",
        "    np.save(\"drive/My Drive/Datacovid_kemal/modelsmodifytwo/my_historyw\"+str(fold)+\".npy\",history.history)\n",
        "    \n",
        "    result.append(model.predict(x_test))\n",
        "    prediction = model.predict(x_test)\n",
        "    Y_pred_classes = np.argmax(prediction,axis = 1) \n",
        "    y_test_classes = np.argmax(y_test,axis = 1)\n",
        "    print(metrics.confusion_matrix(y_test_classes, Y_pred_classes))\n",
        "    print(metrics.classification_report(y_test_classes, Y_pred_classes, digits=2))\n",
        "    conf_mat =confusion_matrix(y_test_classes, Y_pred_classes, labels=[0, 1])\n",
        "    print(conf_mat)\n",
        "    total1=sum(sum(conf_mat))\n",
        "    accuracy1=(conf_mat[0,0]+conf_mat[1,1])/total1\n",
        "    acc_val.append(accuracy1)\n",
        "    print ('Accuracy : ', accuracy1)\n",
        "    probas_ = model.predict_proba(x_test)\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_test_classes, probas_[:, 1],drop_intermediate=False,pos_label=1)\n",
        "    roc_auc = metrics.auc(fpr, tpr)\n",
        "    print(\"Auc-\"+str(fold)+\"=\",roc_auc)\n",
        "    aucs.append(roc_auc)\n",
        "    plt.plot(fpr, tpr, lw=1, alpha=0.3,label='ROC Fold- %d (AUC = %0.2f)' % (fold, roc_auc))\n",
        "    tpr = np.interp(base_fpr, fpr, tpr)\n",
        "    tpr[0] = 0.0\n",
        "    tprs.append(tpr)\n",
        "    fold=fold+1\n",
        "mean_auc=np.mean(aucs)\n",
        "print(\"Mean AUC:\",mean_auc)\n",
        "mean_acc=np.mean(acc_val)\n",
        "print(\"Mean ACC:\",mean_acc)\n",
        "tprs = np.array(tprs)\n",
        "mean_tprs = tprs.mean(axis=0)\n",
        "mean_auc1 = metrics.auc(base_fpr, mean_tprs)\n",
        "std = tprs.std(axis=0)\n",
        "\n",
        "tprs_upper = np.minimum(mean_tprs + std, 1)\n",
        "tprs_lower = mean_tprs - std\n",
        "std_auc = np.std(aucs)\n",
        "plt.plot(base_fpr, mean_tprs, \n",
        "          label='Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
        "          lw=2, alpha=.8)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='Chance', alpha=.8)    \n",
        "plt.xlim([-0.01, 1.01])\n",
        "plt.ylim([-0.01, 1.01])\n",
        "plt.xlabel('False Positive Rate',fontsize=18)\n",
        "plt.ylabel('True Positive Rate',fontsize=18)\n",
        "plt.title('Cross-Validation ROC of Model-4 ')\n",
        "plt.legend(loc=\"lower right\", prop={'size': 15})\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_eKVK1cBVNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ng7I-erM8c2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install ipython-autotime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwTEDQ14YcrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VGGCOV19-NET Summary\n",
        "\n",
        "X = pickle.load(open(\"drive/My Drive/Datacovid_kemal/X_tum_two.pickle\", \"rb\"))\n",
        "y = pickle.load(open(\"drive/My Drive/Datacovid_kemal/Y_tum_two.pickle\", \"rb\"))\n",
        "\n",
        "# normalizing data (a pixel goes from 0 to 255)\n",
        "X = X/255.0   \n",
        "y = to_categorical(y, num_classes = 2)\n",
        "\n",
        "\n",
        "vgg=VGG19(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))   #include_top=False fully connected layer'ı iptal eder\n",
        "vgg_layer_list=vgg.layers\n",
        "model=Sequential()\n",
        "for layer in vgg_layer_list:\n",
        "    model.add(layer)\n",
        "#print(model.summary())\n",
        "\n",
        "for layer in model.layers:\n",
        "    layer.trainable=False\n",
        "\n",
        "numberOfClass=2\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(Dense(256))\n",
        "model.add(Dense(512))\n",
        "model.add(Dense(numberOfClass,activation='softmax'))\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN-TyNmJ0HLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#VGG19 Summary\n",
        "X = pickle.load(open(\"drive/My Drive/Datacovid_kemal/X_tum_two.pickle\", \"rb\"))\n",
        "y = pickle.load(open(\"drive/My Drive/Datacovid_kemal/Y_tum_two.pickle\", \"rb\"))\n",
        "\n",
        "# normalizing data (a pixel goes from 0 to 255)\n",
        "X = X/255.0   \n",
        "y = to_categorical(y, num_classes = 2)\n",
        "\n",
        "\n",
        "vgg=VGG19(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))   #include_top=False fully connected layer'ı iptal eder\n",
        "\n",
        "model=Sequential()\n",
        "for layer in vgg_layer_list:\n",
        "    model.add(layer)\n",
        "#print(model.summary())\n",
        "\n",
        "for layer in model.layers:\n",
        "    layer.trainable=False\n",
        "\n",
        "numberOfClass=2\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096))\n",
        "model.add(Dense(4096))\n",
        "model.add(Dense(numberOfClass,activation='softmax'))\n",
        "print(model.summary())\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}